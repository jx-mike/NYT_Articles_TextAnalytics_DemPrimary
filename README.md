# NYT_Articles_democraticPrimary

In this project, we dived into the 2020 Democratic Primary election and focused on Joe Biden and his biggest competitor Bernie Sanders. We are committed to finding out the correlation between candidate’s performance with media reports mentions and fundraising. To achieve that, we did topic modeling, sentiment analysis and generated word-clouds by using the unstructured data of the New York Times articles since Feb 1 until March 2. We employed logistic regression to find out the accuracy of predicting delegate-won results from fundraising information. 
The topic modeling gave us an idea about what is mainly talked about regarding Joe Biden and Bernie Sanders. 
The sentiment analysis was achieved by calculating scores of polarity and objectivity. We found that on average articles mentioning Joe Biden more than Bernie Sanders tended to be more negative (lower polarity score), while mean objectivity scores didn’t differ and tended to be on the more objective side (less than 0.5).
Regarding the correlation between candidate’s performance in winning a state with fundraising, the logistic regression was applied three times on Biden’s dataset, Sanders’ dataset and an aggregated data set which gave respective accuracies of  0.571, 0.778 and 0.667. This indicates that it can be useful for a candidate campaign team to predict whether the candidate can win a state by looking at how many donors were there in the state and how much they contributed. We also provided suggestions for further improvement on this analysis about collecting and considering more marketing data into the model, like TV ad spendings, number of rallies held, number of direct mail pieces sent out, etc.



## Topic Modeling for News Articles’ Headlines
A word cloud based on the frequency of the words in headlines is plotted at the beginning. From this very initial exploration (Appendix A), we can already see “Sanders” being heavily weighted in NYT’s headlines. We then proceed with topic modeling to gain more insights on how these headlines can be classified into different topics.

Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) are the two major techniques used in this analysis to understand text by modeling topics it represents. Both techniques are unsupervised learning, where headlines with similar “topics” will be clustered together. LSA works similar as PCA does by only keeping the most significant dimensions in transformed space. LDA works under Bayesian assumptions, where it looks at the probability distribution of certain words given the distribution of a particular topic. The main goal is to compare the two techniques and lead our way into the following sections, in which the magnitude and the complexity of the raw text increases dramatically.

In LSA, out of eight topics, two contained “biden” within the top 10 words. On the other hand, “sanders” appeared only once out of the eight topics. This however is counter intuitive from what we saw from the word cloud mentioned above. Meanwhile, in LDA clusters, out of eight topics, “sanders, bernie” showed up in four, whereas “biden” only showed up twice. LSA’s clustering suggests that NYT favors “biden” with underlying topics analysis, however LDA suggests the other way. We then plotted both clusters with 2D representations using t-SNE to assess its corresponding validity. 


## Topic Modeling for Article Body Text
After seeing these trends in just the headlines of articles, our team decided to look deeper at the full body text to determine if there were any clearer ideas of topics that Vice President Biden was mentioned in, as well as see how the trend in prevalence of his versus Senator Sanders’ name held throughout the text. Since this text requires more analysis, stemming was done which caused “sanders” to become “sander” and “bernie” to become “berni”. An initial word cloud shows that while Senator Sander’s name is clearly more prevalent than Vice President Biden’s, their counts are much closer than when looking at headlines. 
When topic modeling was done on the article body text, words were classified into 10 topics and the top 20 words in each topic were examined to get an idea of what each topic represented. Vice President Biden’s name was seen in topics 0 and 4, while Senator Sanders’ name was seen in topics 1, 4, 6, 8 and 9. Topic 0 mentioned words like “campaign”, “senate”, and “family” in addition to Mr. Biden, with nothing standing out as a clear idea of what this topic includes. Topic 4, on the other hand, mentioned not only Sanders and Biden, but also Buttigieg and Warren, along with New Hampshire and Iowa -- most likely about those two first primary states.

## Sentiment Analysis
The New York Times, a leading source of news media for American Democrats, has not officially endorsed a candidate in the Democratic primaries. However, our team decided to perform sentiment analysis on the article body text to determine if the news source is indirectly showing support one way or another. 

Since we were unable to obtain labeled data for training and testing, our team relied on a package called TextBlob, that uses its own knowledge of words and sentiment to calculate two scores for a string: 
 > Polarity - ranging from [-1.0,1.0] with -1.0 being completely negative and +1.0 being completely positive
 > Objectivity - ranging from [0.0,1.0]  with 0.0 being completely objective and 1.0 being completely subjective

Polarity and Objectivity scores were obtained for each article based on the original (unprocessed) text strings. In order to determine if the New York Times treats the candidates differently, appearances of each candidate’s name in an article were counted and if Biden’s name appeared more than Sanders’ then the article received a “1” value in the column called “biden_most”; if Sanders’ appeared more than Bidens’, the column received a “0” value; if mentions were equal, the article was removed from this analysis. In total, there were 724 articles analyzed, of which only 209 mentioned Biden more than Sanders. 

Based on these charts, one can see that on average articles mentioning Joe Biden more than Bernie Sanders tended to be more negative (lower polarity score), while mean objectivity scores didn’t differ and tended to be on the more objective side (less than 0.5). 

## Individual Contribution Analysis
In MongoDB, we stored the information about fundraising and delegates-won results for each candidate in different states. Using these data, we looked at how confident we can be if we predict whether a candidate can win a state by using two features as independent variables, number of unique contributors in the state and total amount of donation raised in the state.

After randomly splitting the training and testing data, the logistic regression model gave an accuracy of 0.571 for Biden data set and 0.778 for Sanders data set. We further aggregated these two data sets by calculating the difference of Biden’s and Sanders’ corresponding values for these two features. In other words, we got two new columns which indicate, for each state in the data set, how much more amount of donations Biden got than Sanders and how many more unique donors Biden got than Sanders. By doing the logistic regression again of these two new features on Biden’s delegate-won results for each state, we got an accuracy of 0.667.
